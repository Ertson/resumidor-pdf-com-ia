import os
import streamlit as st
import fitz  # PyMuPDF
from openai import OpenAI

"""Simple Chat‚Äëwith‚ÄëPDF app for Streamlit Cloud
-------------------------------------------------
Features
--------
‚Ä¢ Upload a PDF
‚Ä¢ Ask free‚Äëform questions about its content
‚Ä¢ Answers generated by OpenAI GPT models (e.g. gpt‚Äë4o‚Äëmini)

HOW IT WORKS
============
1. The PDF text is extracted with PyMuPDF and stored in `st.session_state`.
2. Each user question is sent to the model along with a system prompt that
   instructs it to answer **only** from the provided document text.
3. To keep the prompt within context limits, the document text is truncated
   to `MAX_CHARS`.

For production use on large PDFs you would typically:
   ‚Ä¢ split the document into chunks
   ‚Ä¢ generate embeddings (OpenAIEmbedding, LlamaIndex, etc.)
   ‚Ä¢ perform similarity search to retrieve only the most relevant chunks
   ‚Ä¢ send those chunks, not the whole document, to the model.
This minimalist version keeps things easy to understand.
"""

# ---------- Configuration ----------------------------------------------------
MAX_CHARS = 16000  # truncate doc to avoid context overflow (‚âà12‚Äë13K tokens)
MODEL_NAME = "gpt-4o-mini"  # cheap+fast model; change to gpt‚Äë4o or gpt‚Äë3.5‚Äëturbo

# Read API key ---------------------------------------------------------------
OPENAI_API_KEY = st.secrets.get("OPENAI_API_KEY") or os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    st.error("‚ö†Ô∏è  Defina OPENAI_API_KEY em .streamlit/secrets.toml ou vari√°vel de ambiente")
    st.stop()

client = OpenAI(api_key=OPENAI_API_KEY)

# ---------- Helper functions -------------------------------------------------

def extract_pdf_text(uploaded_file: st.runtime.uploaded_file_manager.UploadedFile) -> str:
    """Return entire text of a PDF"""
    doc = fitz.open(stream=uploaded_file.read(), filetype="pdf")
    text = "".join(page.get_text() for page in doc)
    return text


def ask_gpt(question: str, context: str) -> str:
    """Ask OpenAI chat model with document context, return answer string"""
    system_prompt = (
        "Voc√™ √© um assistente que responde somente com base no PDF fornecido. "
        "Se a resposta n√£o estiver claramente presente no texto, diga educadamente que n√£o sabe."
    )

    user_prompt = f"Documento:\n{context}\n\nPergunta do usu√°rio: {question}"

    response = client.chat.completions.create(
        model=MODEL_NAME,
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt},
        ],
        max_tokens=512,
        temperature=0.2,
    )
    return response.choices[0].message.content.strip()

# ---------- UI ----------------------------------------------------------------
st.set_page_config(page_title="Chat com PDF (OpenAI)", layout="centered")
st.title("üìÑ Chat com seu PDF usando IA")

uploaded_file = st.file_uploader("1Ô∏è‚É£  Fa√ßa upload do seu PDF", type="pdf")

if uploaded_file and "doc_text" not in st.session_state:
    with st.spinner("Extraindo texto do PDF ‚Ä¶"):
        st.session_state.doc_text = extract_pdf_text(uploaded_file)[:MAX_CHARS]
    st.success("Texto carregado! Agora fa√ßa perguntas.")

if "doc_text" in st.session_state:
    if "messages" not in st.session_state:
        st.session_state.messages = []  # list of (role, content)

    # Display previous conversation
    for role, msg in st.session_state.messages:
        if role == "user":
            st.chat_message("user").write(msg)
        else:
            st.chat_message("assistant").write(msg)

    # Chat input
    user_q = st.chat_input("Digite sua pergunta sobre o PDF e pressione Enter‚Ä¶")
    if user_q:
        st.session_state.messages.append(("user", user_q))
        st.chat_message("user").write(user_q)

        with st.spinner("Consultando IA‚Ä¶"):
            answer = ask_gpt(user_q, st.session_state.doc_text)
        st.session_state.messages.append(("assistant", answer))
        st.chat_message("assistant").write(answer)

else:
    st.info("üì•  Primeiro, envie um PDF para iniciar o chat.")
